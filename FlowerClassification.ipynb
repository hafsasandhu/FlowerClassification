{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4cbPha0t9-z",
        "outputId": "0bb39fc2-07e5-41f0-fbbc-e0820a80eb2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train {'dandelion': 452, 'daisy': 350, 'sunflower': 346, 'tulip': 424, 'rose': 347}\n",
            "val {'dandelion': 194, 'daisy': 151, 'sunflower': 149, 'tulip': 183, 'rose': 150}\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from pathlib import Path\n",
        "import shutil, random\n",
        "\n",
        "root = Path(kagglehub.dataset_download(\"imsparsh/flowers-dataset\"))\n",
        "\n",
        "src = (root / \"train\") if (root / \"train\").is_dir() else root\n",
        "\n",
        "classes = [d.name for d in src.iterdir()\n",
        "           if d.is_dir() and d.name not in (\"train\",\"test\")]\n",
        "\n",
        "out = Path(\"flower_dataset\")\n",
        "for split in (\"train\",\"val\"):\n",
        "    for cls in classes:\n",
        "        (out / split / cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "random.seed(42)\n",
        "for cls in classes:\n",
        "    imgs = list((src/cls).glob(\"*.*\"))\n",
        "    random.shuffle(imgs)\n",
        "    cut = int(0.7 * len(imgs))\n",
        "    for img in imgs[:cut]:\n",
        "        shutil.copy2(img, out/\"train\"/cls/img.name)\n",
        "    for img in imgs[cut:]:\n",
        "        shutil.copy2(img, out/\"val\"/cls/img.name)\n",
        "\n",
        "for split in (\"train\",\"val\"):\n",
        "    print(split, {cls: len(list((out/split/cls).iterdir())) for cls in classes})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IR_kr63wFWQ",
        "outputId": "b1a86c15-f939-4070-ac37-b118bf0e4f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected classes: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
            "Epoch 1/5 | Train loss=1.5968, acc=0.3538 | Val loss=1.5716, acc=0.6227\n",
            "Epoch 2/5 | Train loss=1.5344, acc=0.6660 | Val loss=1.4025, acc=0.7473\n",
            "Epoch 3/5 | Train loss=1.3863, acc=0.7551 | Val loss=1.2055, acc=0.8162\n",
            "Epoch 4/5 | Train loss=1.2159, acc=0.8103 | Val loss=1.0417, acc=0.8634\n",
            "Epoch 5/5 | Train loss=1.0572, acc=0.8213 | Val loss=0.8852, acc=0.8863\n",
            "Training complete. Best validation accuracy: 0.8863\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# -------- ECA Attention Module --------\n",
        "class ECALayer(nn.Module):\n",
        "    def __init__(self, channel, k_size=None):\n",
        "        super().__init__()\n",
        "        if k_size is None:\n",
        "            t = int(abs((torch.log2(torch.tensor(channel, dtype=torch.float32)) / 2 + 1)))\n",
        "            k_size = t if t % 2 else t + 1\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size-1)//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = y.view(x.size(0), 1, x.size(1))\n",
        "        y = self.conv(y)\n",
        "        y = self.sigmoid(y).view(x.size(0), x.size(1), 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "# -------- Opti-SA Model Definition --------\n",
        "class OptiSA(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        backbone = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "        self.features = nn.Sequential(\n",
        "            backbone.conv1,\n",
        "            backbone.maxpool,\n",
        "            backbone.stage2,\n",
        "            backbone.stage3,\n",
        "            backbone.stage4,\n",
        "            backbone.conv5,\n",
        "        )\n",
        "        in_feats = backbone.fc.in_features\n",
        "        self.eca = ECALayer(channel=in_feats)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(in_feats, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.eca(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "def train_and_validate(data_dir='flower_dataset', batch_size=45, epochs=5, lr=1e-4):\n",
        "    for split in ['train', 'val']:\n",
        "        for junk in ['train', 'test']:\n",
        "            path = os.path.join(data_dir, split, junk)\n",
        "            if os.path.isdir(path):\n",
        "                shutil.rmtree(path)\n",
        "\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ColorJitter(0.3, 0.3),\n",
        "        transforms.RandomApply([transforms.GaussianBlur(3)], p=0.3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5] * 3, [0.5] * 3),\n",
        "    ])\n",
        "    val_tf = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5] * 3, [0.5] * 3),\n",
        "    ])\n",
        "\n",
        "    train_path = os.path.join(data_dir, 'train')\n",
        "    val_path = os.path.join(data_dir, 'val')\n",
        "    train_ds = datasets.ImageFolder(train_path, transform=train_tf)\n",
        "    val_ds = datasets.ImageFolder(val_path, transform=val_tf)\n",
        "    print(f\"Detected classes: {train_ds.classes}\")\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = OptiSA(num_classes=len(train_ds.classes)).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = correct = total = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += imgs.size(0)\n",
        "        train_loss = total_loss / total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_loss = correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item() * imgs.size(0)\n",
        "                correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                total += imgs.size(0)\n",
        "        val_loss = total_loss / total\n",
        "        val_acc = correct / total\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        print(f\"Epoch {epoch}/{epochs} | \"\n",
        "              f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "              f\"Val loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_opti_sa.pth')\n",
        "\n",
        "    print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "train_and_validate(data_dir='flower_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3ZLeEpZ3KfR",
        "outputId": "bc849b3c-984f-42cf-c4c3-5c37c7fc1869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class: sunflower  (p=0.3386)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# -------- ECA Attention Module --------\n",
        "class ECALayer(nn.Module):\n",
        "    def __init__(self, channel, k_size=None):\n",
        "        super().__init__()\n",
        "        if k_size is None:\n",
        "            t = int(abs((torch.log2(torch.tensor(channel, dtype=torch.float32)) / 2 + 1)))\n",
        "            k_size = t if t % 2 else t + 1\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size-1)//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = y.view(x.size(0), 1, x.size(1))\n",
        "        y = self.conv(y)\n",
        "        y = self.sigmoid(y).view(x.size(0), x.size(1), 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class OptiSA(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        backbone = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "        self.features = nn.Sequential(\n",
        "            backbone.conv1,\n",
        "            backbone.maxpool,\n",
        "            backbone.stage2,\n",
        "            backbone.stage3,\n",
        "            backbone.stage4,\n",
        "            backbone.conv5,\n",
        "        )\n",
        "        in_feats = backbone.fc.in_features\n",
        "        self.eca = ECALayer(channel=in_feats)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(in_feats, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.eca(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = OptiSA(num_classes=5).to(device)\n",
        "model.load_state_dict(torch.load('best_opti_sa.pth', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "img_path = '/content/sun.jpeg'\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "x = val_tf(img).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(x)\n",
        "    probs  = torch.softmax(logits, dim=1)\n",
        "    pred_idx = probs.argmax(dim=1).item()\n",
        "\n",
        "classes = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "print(f\"Predicted class: {classes[pred_idx]}  (p={probs[0,pred_idx]:.4f})\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
